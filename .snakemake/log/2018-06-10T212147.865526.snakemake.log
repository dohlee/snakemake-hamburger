Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	make_hamburger
	1	roast_onion
	2

rule roast_onion:
    input: dohoon.onion
    output: dohoon.roasted_onion
    jobid: 5
    wildcards: name=dohoon

/home/lee/.env/lab/bin/python3.5 /mnt/c/Users/lee/Desktop/snakemake-hamburger/onion/roast/.snakemake.19d1yaf9.wrapper.py
    Error in rule roast_onion:
        jobid: 5
        output: dohoon.roasted_onion

RuleException:
CalledProcessError in line 74 of /mnt/c/Users/lee/Desktop/snakemake-hamburger/Snakefile:
Command ' set -euo pipefail;  /home/lee/.env/lab/bin/python3.5 /mnt/c/Users/lee/Desktop/snakemake-hamburger/onion/roast/.snakemake.19d1yaf9.wrapper.py ' returned non-zero exit status 1
  File "/mnt/c/Users/lee/Desktop/snakemake-hamburger/Snakefile", line 74, in __rule_roast_onion
  File "/usr/lib/python3.5/concurrent/futures/thread.py", line 55, in run
Removing output files of failed job roast_onion since they might be corrupted:
dohoon.roasted_onion
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /mnt/c/Users/lee/Desktop/snakemake-hamburger/.snakemake/log/2018-06-10T212147.865526.snakemake.log
